{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63ed3a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F_onewayResult(statistic=2.7629002184715685, pvalue=0.022747839014187386)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('all_metrics.csv')\n",
    "\n",
    "# Drop 'Unnamed: 0' column\n",
    "df = df.drop(columns='Unnamed: 0')\n",
    "\n",
    "# Replace NaN values with 0\n",
    "df = df.fillna(0)\n",
    "\n",
    "# Create a pivot table with Models as rows, Datasets as columns, and mean Accuracy as values\n",
    "heatmap_data = df.pivot_table(values='Accuracy', index='Model', columns='Dataset')\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(heatmap_data, annot=True, cmap='YlGnBu', fmt=\".2f\", linewidths=.5)\n",
    "plt.title('Heatmap of Model Performance (Accuracy)')\n",
    "plt.savefig('heatmap.png', dpi=300)  # Save the plot as a high-quality PNG image\n",
    "plt.close()\n",
    "\n",
    "# Select the columns to plot\n",
    "cols_to_plot = ['Accuracy', 'Precision (macro)', 'Recall (macro)', 'F1-score (macro)', 'AUC-ROC (macro)']\n",
    "\n",
    "# Melt the dataframe to have one row per model per metric\n",
    "df_melted = df.melt(id_vars='Model', value_vars=cols_to_plot, var_name='Metric', value_name='Score')\n",
    "\n",
    "# Plot the boxplots\n",
    "plt.figure(figsize=(15, 10))\n",
    "sns.boxplot(data=df_melted, x='Score', y='Metric', hue='Model')\n",
    "plt.title('Distribution of Performance Metrics for Each Model')\n",
    "plt.legend(loc='lower right')\n",
    "plt.savefig('boxplots.png', dpi=300)  # Save the plot as a high-quality PNG image\n",
    "plt.close()\n",
    "\n",
    "# Calculate the correlation matrix for the selected metrics\n",
    "correlation_matrix = df[cols_to_plot].corr()\n",
    "\n",
    "# Plot the correlation matrix as a heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1, square=True)\n",
    "plt.title('Correlation Matrix of Performance Metrics')\n",
    "plt.savefig('correlation_matrix.png', dpi=300)  # Save the plot as a high-quality PNG image\n",
    "plt.close()\n",
    "\n",
    "# Define the columns to include in PCA\n",
    "cols_to_include = ['Accuracy', 'Precision (macro)', 'Recall (macro)', 'F1-score (macro)', 'AUC-ROC (macro)']\n",
    "\n",
    "# Perform PCA\n",
    "pca = PCA(n_components=2)\n",
    "pca_results = pca.fit_transform(df[cols_to_include])\n",
    "\n",
    "# Create a dataframe with the PCA results\n",
    "df_pca = pd.DataFrame(data=pca_results, columns=['PC1', 'PC2'])\n",
    "df_pca['Model'] = df['Model']\n",
    "\n",
    "# Plot the PCA results\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.scatterplot(data=df_pca, x='PC1', y='PC2', hue='Model')\n",
    "plt.title('PCA of Model Performance')\n",
    "plt.savefig('pca.png', dpi=300)  # Save the plot as a high-quality PNG image\n",
    "plt.close()\n",
    "\n",
    "# Calculate the mean ranking for each model across all metrics\n",
    "rankings = df[cols_to_plot].rank(method='min').mean(axis=1)\n",
    "df['Ranking'] = rankings\n",
    "\n",
    "# Group by model and calculate the mean ranking for each model\n",
    "model_rankings = df.groupby('Model')['Ranking'].mean()\n",
    "\n",
    "# Sort by ranking\n",
    "model_rankings = model_rankings.sort_values()\n",
    "\n",
    "# Plot the rankings\n",
    "model_rankings.plot(kind='barh', figsize=(10, 6))\n",
    "plt.title('Overall Ranking of Models')\n",
    "plt.xlabel('Mean Ranking')\n",
    "plt.ylabel('Model')\n",
    "plt.savefig('rankings.png', dpi=300)  # Save the plot as a high-quality PNG image\n",
    "plt.close()\n",
    "\n",
    "# Perform ANOVA\n",
    "anova_results = stats.f_oneway(*(df[df['Model'] == model]['Accuracy'] for model in df['Model'].unique()))\n",
    "\n",
    "print(anova_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc964ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('/mnt/data/all_metrics.csv')\n",
    "\n",
    "# Drop 'Unnamed: 0' column\n",
    "df = df.drop(columns='Unnamed: 0')\n",
    "\n",
    "# Replace NaN values with 0\n",
    "df = df.fillna(0)\n",
    "\n",
    "# Create a pivot table with Models as rows, Datasets as columns, and mean Accuracy as values\n",
    "heatmap_data = df.pivot_table(values='Accuracy', index='Model', columns='Dataset')\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(heatmap_data, annot=True, cmap='YlGnBu', fmt=\".2f\", linewidths=.5)\n",
    "plt.title('Heatmap of Model Performance (Accuracy)')\n",
    "plt.show()\n",
    "\n",
    "# Select the columns to plot\n",
    "cols_to_plot = ['Accuracy', 'Precision (macro)', 'Recall (macro)', 'F1-score (macro)', 'AUC-ROC (macro)']\n",
    "\n",
    "# Melt the dataframe to have one row per model per metric\n",
    "df_melted = df.melt(id_vars='Model', value_vars=cols_to_plot, var_name='Metric', value_name='Score')\n",
    "\n",
    "# Plot the boxplots\n",
    "plt.figure(figsize=(15, 10))\n",
    "sns.boxplot(data=df_melted, x='Score', y='Metric', hue='Model')\n",
    "plt.title('Distribution of Performance Metrics for Each Model')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "# Calculate the correlation matrix for the selected metrics\n",
    "correlation_matrix = df[cols_to_plot].corr()\n",
    "\n",
    "# Plot the correlation matrix as a heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1, square=True)\n",
    "plt.title('Correlation Matrix of Performance Metrics')\n",
    "plt.show()\n",
    "\n",
    "# Perform PCA\n",
    "pca = PCA(n_components=2)\n",
    "pca_results = pca.fit_transform(df[cols_to_include])\n",
    "\n",
    "# Create a dataframe with the PCA results\n",
    "df_pca = pd.DataFrame(data=pca_results, columns=['PC1', 'PC2'])\n",
    "df_pca['Model'] = df['Model']\n",
    "\n",
    "# Plot the PCA results\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.scatterplot(data=df_pca, x='PC1', y='PC2', hue='Model')\n",
    "plt.title('PCA of Model Performance')\n",
    "plt.show()\n",
    "\n",
    "# Calculate the mean ranking for each model across all metrics\n",
    "rankings = df[cols_to_plot].rank(method='min').mean(axis=1)\n",
    "df['Ranking'] = rankings\n",
    "\n",
    "# Group by model and calculate the mean ranking for each model\n",
    "model_rankings = df.groupby('Model')['Ranking'].mean()\n",
    "\n",
    "# Sort by ranking\n",
    "model_rankings = model_rankings.sort_values()\n",
    "\n",
    "# Plot the rankings\n",
    "model_rankings.plot(kind='barh', figsize=(10, 6))\n",
    "plt.title('Overall Ranking of Models')\n",
    "plt.xlabel('Mean Ranking')\n",
    "plt.ylabel('Model')\n",
    "plt.show()\n",
    "\n",
    "# Perform ANOVA\n",
    "anova_results = stats.f_oneway(*(df[df['Model'] == model]['Accuracy'] for model in df['Model'].unique()))\n",
    "\n",
    "print(anova_results)\n",
    "\n",
    "def plot_model_performance(model, metric):\n",
    "    \"\"\"\n",
    "    Plot the performance of a selected model on a selected metric.\n",
    "    \n",
    "    Parameters:\n",
    "    model (str): The name of the model.\n",
    "    metric (str): The name of the metric.\n",
    "    \"\"\"\n",
    "    # Select the data for the model and metric\n",
    "    data = df[df['Model'] == model][metric]\n",
    "    \n",
    "    # Plot the data\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x=data.index, y=data, color='skyblue')\n",
    "    plt.title(f'{model} Performance on {metric}')\n",
    "    plt.xlabel('Run')\n",
    "    plt.ylabel(metric)\n",
    "    plt.show()\n",
    "\n",
    "# Test the function with the 'RandomForest' model and 'Accuracy' metric\n",
    "plot_model_performance('RandomForest', 'Accuracy')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
