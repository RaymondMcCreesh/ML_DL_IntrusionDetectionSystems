{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1W39UvzW2oHyVFqBqhbkcWTwQqkwVPqOJ","timestamp":1685460760557},{"file_id":"1cVr9spVpXLyQ3YB1n_CLqEZ--akyS-Tb","timestamp":1682190446311},{"file_id":"1r4R-Yg92t4wFZGTSz08-5PQ23Y3qil4s","timestamp":1682182067106}],"machine_shape":"hm","gpuType":"V100"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"LcDTEI_Fa9B3","executionInfo":{"status":"ok","timestamp":1690814437009,"user_tz":-60,"elapsed":34520,"user":{"displayName":"Ray Mac Raois","userId":"15450155140228807087"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"28500549-6df0-4eaf-b5d3-6501017b0d66"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"RMTiyM1Mz4fs","executionInfo":{"status":"ok","timestamp":1690814492291,"user_tz":-60,"elapsed":10519,"user":{"displayName":"Ray Mac Raois","userId":"15450155140228807087"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder, StandardScaler\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve, auc, precision_recall_curve, average_precision_score\n","from sklearn.preprocessing import label_binarize\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","def print_score(y_pred, y_real, y_score, label_encoder, model_name):\n","    data = []\n","\n","    data.append([\"Accuracy\", accuracy_score(y_real, y_pred)])\n","    data.append([\"Precision (macro)\", precision_score(y_real, y_pred, average='macro', zero_division=1)])\n","    data.append([\"Recall (macro)\", recall_score(y_real, y_pred, average='macro', zero_division=0)])\n","    data.append([\"F1-score (macro)\", f1_score(y_real, y_pred, average='macro', zero_division=0)])\n","    data.append([\"AUC-ROC (macro)\", roc_auc_score(y_real, y_score, multi_class='ovr', average='macro')])\n","\n","    for i in range(len(label_encoder.classes_)):\n","        class_name = label_encoder.inverse_transform([i])[0]\n","        data.append([f\"Precision ({class_name})\", precision_score(y_real, y_pred, labels=[i], average='weighted', zero_division=1)])\n","        data.append([f\"Recall ({class_name})\", recall_score(y_real, y_pred, labels=[i], average='weighted', zero_division=0)])\n","        data.append([f\"F1-score ({class_name})\", f1_score(y_real, y_pred, labels=[i], average='weighted', zero_division=0)])\n","\n","    score_df = pd.DataFrame(data, columns=[\"Metric\", \"Value\"])\n","    display(score_df)\n","\n","    # Save the score DataFrame to a CSV file\n","    score_df.to_csv(f\"/content/drive/MyDrive/Results/{model_name}_CICIDS_metrics.csv\", index=False)\n","\n","\n","def plot_roc_curve(y_true, y_score, label_encoder, model_name):\n","    n_classes = len(label_encoder.classes_)\n","\n","    if n_classes == 2:\n","        fpr, tpr, _ = roc_curve(y_true, y_score[:, 1])\n","        roc_auc = auc(fpr, tpr)\n","\n","        plt.figure(figsize=(10, 6))\n","        lw = 2\n","        plt.plot(fpr, tpr, color='darkorange', lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n","        plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n","        plt.xlim([0.0, 1.0])\n","        plt.ylim([0.0, 1.05])\n","        plt.xlabel('False Positive Rate')\n","        plt.ylabel('True Positive Rate')\n","        plt.title('Receiver Operating Characteristic (ROC) curve')\n","        plt.legend(loc=\"best\", bbox_to_anchor=(1.05, 1), borderaxespad=0.)\n","        plt.savefig(f\"/content/drive/MyDrive/Results/{model_name}_CICIDS_roc_curve.png\", bbox_inches='tight')  # Move this line before plt.show()\n","        plt.show()\n","    else:\n","        fpr = dict()\n","        tpr = dict()\n","        roc_auc = dict()\n","        for i in range(n_classes):\n","            fpr[i], tpr[i], _ = roc_curve(y_true, y_score[:, i], pos_label=i)\n","            roc_auc[i] = auc(fpr[i], tpr[i])\n","\n","        plt.figure(figsize=(10, 6))\n","        for i in range(n_classes):\n","            class_name = label_encoder.inverse_transform([i])[0]\n","            plt.plot(fpr[i], tpr[i], lw=2, label='ROC curve of class {0} (area = {1:0.2f})'.format(class_name, roc_auc[i]))\n","\n","        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n","        plt.xlim([0.0, 1.0])\n","        plt.ylim([0.0, 1.05])\n","        plt.xlabel('False Positive Rate')\n","        plt.ylabel('True Positive Rate')\n","        plt.title('Receiver Operating Characteristic (ROC) curve for multi-class')\n","        plt.legend(loc=\"best\", bbox_to_anchor=(1.05, 1), borderaxespad=0.)\n","        plt.savefig(f\"/content/drive/MyDrive/Results/{model_name}_CICIDS_roc_curve.png\", bbox_inches='tight')  # Move this line before plt.show() and correct the filename\n","        plt.show()\n","\n","\n","from sklearn.metrics import PrecisionRecallDisplay\n","\n","def plot_precision_recall_curve(y_true, y_score, label_encoder, model_name):\n","    n_classes = len(label_encoder.classes_)\n","\n","    if n_classes == 2:\n","        precision, recall, _ = precision_recall_curve(y_true, y_score[:, 1])\n","        average_precision = average_precision_score(y_true, y_score[:, 1])\n","\n","        plt.figure(figsize=(10, 6))  # Change the figure size here\n","        plt.step(recall, precision, where='post')\n","        plt.xlabel('Recall')\n","        plt.ylabel('Precision')\n","        plt.ylim([0.0, 1.05])\n","        plt.xlim([0.0, 1.0])\n","        plt.title('2-class Precision-Recall curve: AP={0:0.2f}'.format(average_precision))\n","        plt.legend(loc=\"best\", bbox_to_anchor=(1.05, 1), borderaxespad=0.)\n","        plt.savefig(f\"/content/drive/MyDrive/Results/{model_name}_CICIDS_precision_recall_curve.png\", bbox_inches='tight')  # Move this line before plt.show() and correct the filename\n","        plt.show()\n","    else:\n","        y_true_binarized = label_binarize(y_true, classes=list(range(n_classes)))\n","        precision = dict()\n","        recall = dict()\n","        average_precision = dict()\n","\n","        for i in range(n_classes):\n","            precision[i], recall[i], _ = precision_recall_curve(y_true_binarized[:, i], y_score[:, i])\n","            average_precision[i] = average_precision_score(y_true_binarized[:, i], y_score[:, i], average=None)\n","\n","        # Plot Precision-Recall curve for each class\n","        plt.figure(figsize=(10, 6))  # Change the figure size here\n","        for i in range(n_classes):\n","            disp = PrecisionRecallDisplay(precision=precision[i], recall=recall[i])\n","            class_name = label_encoder.inverse_transform([i])[0]\n","            disp.plot(ax=plt.gca(), label='Precision-recall curve of class {0} (AP = {1:0.2f})'.format(class_name, average_precision[i]))\n","\n","        plt.xlabel('Recall')\n","        plt.ylabel('Precision')\n","        plt.ylim([0.0, 1.05])\n","        plt.xlim([0.0, 1.0])\n","        plt.title('Precision-Recall curve for multi-class')\n","        plt.legend(loc=\"best\", bbox_to_anchor=(1.05, 1), borderaxespad=0.)\n","        plt.savefig(f\"/content/drive/MyDrive/Results/{model_name}_CICIDS_precision_recall_curve.png\", bbox_inches='tight')  # Move this line before plt.show() and correct the filename\n","        plt.show()\n","\n","def plot_class_accuracy(y_true, y_pred, label_encoder, model_name):\n","    n_classes = len(label_encoder.classes_)\n","    class_counts = np.zeros(n_classes)\n","    class_corrects = np.zeros(n_classes)\n","\n","    for t, p in zip(y_true, y_pred):\n","        class_counts[t] += 1\n","        if t == p:\n","            class_corrects[t] += 1\n","\n","    class_accuracies = class_corrects / class_counts\n","    class_names = label_encoder.inverse_transform(range(n_classes))\n","\n","    plt.figure(figsize=(10, 6))\n","    plt.bar(class_names, class_accuracies)\n","    plt.xlabel('Class')\n","    plt.ylabel('Accuracy')\n","    plt.title('Accuracy per Class')\n","    plt.xticks(rotation=45)\n","    plt.ylim([0.0, 1.05])\n","    plt.savefig(f\"/content/drive/MyDrive/Results/{model_name}_CICIDS_class_accuracy.png\", bbox_inches='tight')  # Move this line before plt.show()\n","    plt.show()\n","\n","def plot_class_f1_score(y_true, y_pred, label_encoder, model_name):\n","    n_classes = len(label_encoder.classes_)\n","    f1_scores = []\n","\n","    for i in range(n_classes):\n","        class_f1_score = f1_score(y_true, y_pred, labels=[i], average='weighted')\n","        f1_scores.append(class_f1_score)\n","\n","    class_names = label_encoder.inverse_transform(range(n_classes))\n","\n","    plt.figure(figsize=(10, 6))\n","    plt.bar(class_names, f1_scores)\n","    plt.xlabel('Class')\n","    plt.ylabel('F1-score')\n","    plt.title('F1-score per Class')\n","    plt.xticks(rotation=45)\n","    plt.ylim([0.0, 1.05])\n","    fig = plt.gcf()  # Get the current figure\n","    plt.show()\n","\n","    # Save the figure to an image file\n","    fig.savefig(f\"/content/drive/MyDrive/Results/{model_name}_CICIDS_class_f1_score.png\", bbox_inches='tight')\n","\n","# Load the dataset\n","file_path = '/content/drive/MyDrive/Data/preprocessed2_CIC_IDS-2017_data.csv'\n","df = pd.read_csv(file_path)\n"]},{"cell_type":"code","source":["import tensorflow as tf\n","\n","embedding_size = 128  # Choose the desired embedding size\n","X = df.iloc[:, :-1]  # Get all columns except the last one as input features\n","num_features = X.shape[1]\n","num_samples = X.shape[0]  # Get the number of samples\n","\n","# Define the input and embedding layer\n","input_features = tf.keras.layers.Input(shape=(num_features,))\n","embedding_layer = tf.keras.layers.Dense(embedding_size, activation='relu')\n","embeddings = embedding_layer(input_features)\n","\n","# Positional encoding functions\n","def get_angles(pos, i, d_model):\n","    angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n","    return pos * angle_rates\n","\n","def positional_encoding(position, d_model):\n","    angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n","                            np.arange(d_model)[np.newaxis, :],\n","                            d_model)\n","    pos_encoding = np.zeros((position, d_model), dtype=np.float32)\n","    pos_encoding[0::2, :] = np.sin(angle_rads[0::2, :])\n","    pos_encoding[1::2, :] = np.cos(angle_rads[1::2, :])\n","    return tf.cast(pos_encoding, dtype=tf.float32)\n","\n","# Add positional encoding to the embeddings\n","position = num_features  # Number of positions equal to the number of samples\n","embeddings_with_pos_enc = positional_encoding(position, embedding_size) + embeddings\n"],"metadata":{"id":"yOVTAnzeteQu","executionInfo":{"status":"ok","timestamp":1690814502188,"user_tz":-60,"elapsed":9907,"user":{"displayName":"Ray Mac Raois","userId":"15450155140228807087"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# Import necessary libraries\n","import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report\n","import tensorflow as tf\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, Dense, Dropout, LayerNormalization\n","from tensorflow.keras.layers.experimental.preprocessing import Normalization\n","from tensorflow.keras.layers import MultiHeadAttention, GlobalAveragePooling1D\n","from tensorflow.keras.layers import Lambda\n","\n","\n","def position_wise_feed_forward(inputs, d_ff):\n","    x = Dense(units=d_ff, activation='relu')(inputs)\n","    x = Dense(units=d_model)(x)\n","    return x\n","\n","def multi_head_self_attention(inputs, d_model, num_heads, dropout_rate):\n","    depth = d_model // num_heads\n","    attention = MultiHeadAttention(num_heads=num_heads, key_dim=depth, dropout=0.3)\n","    x = attention(inputs, inputs)\n","    return x\n","\n","def encoder_layer(inputs, d_model, num_heads, d_ff, dropout_rate=0.3):\n","    x = multi_head_self_attention(inputs, d_model, num_heads, dropout_rate)\n","    x = Dropout(dropout_rate)(x)\n","    x = LayerNormalization(epsilon=1e-6)(inputs + x)\n","\n","    ff = position_wise_feed_forward(x, d_ff)\n","    x = Dropout(dropout_rate)(ff)\n","    x = LayerNormalization(epsilon=1e-6)(x + ff)\n","\n","    return x\n","\n","class BroadcastPositionalEncoding(tf.keras.layers.Layer):\n","    def __init__(self, position, d_model):\n","        super(BroadcastPositionalEncoding, self).__init__()\n","        self.pos_encoding = positional_encoding(position, d_model)\n","\n","    def call(self, inputs):\n","        shape = tf.shape(inputs)\n","        return inputs + self.pos_encoding[:shape[0], :shape[1]]\n","\n","def create_transformer_ids_model(input_shape, d_model, d_ff, num_heads, num_layers, num_classes, dropout_rate=0.3):\n","    inputs = Input(shape=input_shape)\n","\n","    # Embedding layer\n","    embedding_layer = Dense(d_model, activation='relu')\n","    embeddings = embedding_layer(inputs)\n","\n","    # Reshape the embeddings to be 3D tensor.\n","    x = tf.expand_dims(embeddings, axis=1)\n","\n","    # Broadcast Positional Encoding\n","    x = BroadcastPositionalEncoding(input_shape[0], d_model)(x) # Apply it on 'x', not 'embeddings'\n","\n","\n","    # Encoder layers\n","    for _ in range(num_layers):\n","        x = encoder_layer(x, d_model, num_heads, d_ff, dropout_rate)\n","\n","    # Apply GlobalAveragePooling1D\n","    x = GlobalAveragePooling1D()(x)\n","    x = Dropout(dropout_rate)(x)\n","\n","    # Final softmax layer to predict num_classes\n","    outputs = Dense(units=num_classes - 1)(x)\n","    print(\"Shape of model output before softmax: \", outputs.shape)\n","    outputs = tf.keras.layers.Softmax(axis=-1)(outputs)\n","\n","    model = Model(inputs=inputs, outputs=outputs)\n","    return model\n","\n","# Preprocess the CIC-IDS-2017 dataset\n","le = LabelEncoder()\n","df[' Label'] = le.fit_transform(df[' Label'])\n","\n","X = df.iloc[:, :-1].values\n","y = df.iloc[:, -1].values\n","\n","print(\"Shape of Input Data (Features): \", X.shape)\n","print(\"Shape of Output Data (Labels): \", y.shape)\n","\n","# Apply feature selection, normalization, etc.\n","scaler = StandardScaler()\n","X = scaler.fit_transform(X)\n","\n","# Split the data into train and test sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Ensure labels (y_train and y_test) are integer-encoded\n","assert np.issubdtype(y_train.dtype, np.integer), \"y_train should contain integer values\"\n","assert np.issubdtype(y_test.dtype, np.integer), \"y_test should contain integer values\"\n","\n","# Ensure there are no missing or corrupted values in input data (X_train and X_test)\n","assert not np.isnan(X_train).any(), \"X_train contains NaN values\"\n","assert not np.isnan(X_test).any(), \"X_test contains NaN values\"\n","assert not np.isinf(X_train).any(), \"X_train contains infinite values\"\n","assert not np.isinf(X_test).any(), \"X_test contains infinite values\"\n","# Create and compile the model\n","input_shape = X.shape[1:]\n","print(\"Input Shape for Model: \", input_shape)\n","d_model = 128  # Select an embedding size for the model\n","d_ff = 256\n","num_heads = 4\n","num_layers = 4\n","num_classes = len(np.unique(y))\n","print(\"Number of classes: \", num_classes)\n","\n","model = create_transformer_ids_model(input_shape, d_model, d_ff, num_heads, num_layers, num_classes)\n","model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","\n","model.summary()\n","\n","# Train the Transformer-based IDS model\n","batch_size = 64\n","epochs = 10\n","\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","\n","# Define the checkpoint callback\n","checkpoint = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n","\n","# Learning rate scheduler\n","def learning_rate_scheduler(epoch, lr):\n","    if epoch < 10:\n","        return lr  # Keep the initial learning rate for the first 10 epochs\n","    else:\n","        return lr * tf.math.exp(-0.1)  # Exponential decay for learning rate after 10 epochs\n","\n","# Early stopping\n","early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\n","\n","# Learning rate warmup\n","def learning_rate_warmup_scheduler(epoch, lr):\n","    if epoch < 5:\n","        return lr * (epoch + 1) / 5\n","    else:\n","        return lr\n","\n","# Create and compile the model\n","model = create_transformer_ids_model(input_shape, d_model, d_ff, num_heads, num_layers, num_classes)\n","optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n","model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","\n","# Train the model with the callbacks\n","model.fit(\n","    X_train, y_train,\n","    validation_data=(X_test, y_test),\n","    epochs=50,\n","    batch_size=64,\n","    callbacks=[\n","        tf.keras.callbacks.LearningRateScheduler(learning_rate_scheduler),\n","        early_stopping,\n","        tf.keras.callbacks.LearningRateScheduler(learning_rate_warmup_scheduler),\n","        checkpoint\n","    ]\n",")\n","\n","# Load the saved weights into a new model\n","model.load_weights('best_model.h5')\n","\n","\n","# Evaluate the model\n","y_pred = np.argmax(model.predict(X_test), axis=-1)\n","print(\"Classification Report:\")\n","print(classification_report(y_test, y_pred))\n","\n","# Calculate prediction probabilities\n","y_score = model.predict(X_test)\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OFgGoEdEz_WF","outputId":"e6a6d9d9-c618-4d34-8031-66939ea2e309"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of Input Data (Features):  (655839, 70)\n","Shape of Output Data (Labels):  (655839,)\n","Input Shape for Model:  (70,)\n","Number of classes:  15\n","Shape of model output before softmax:  (None, 14)\n","Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_2 (InputLayer)           [(None, 70)]         0           []                               \n","                                                                                                  \n"," dense_1 (Dense)                (None, 128)          9088        ['input_2[0][0]']                \n","                                                                                                  \n"," tf.expand_dims (TFOpLambda)    (None, 1, 128)       0           ['dense_1[0][0]']                \n","                                                                                                  \n"," broadcast_positional_encoding   (None, None, 128)   0           ['tf.expand_dims[0][0]']         \n"," (BroadcastPositionalEncoding)                                                                    \n","                                                                                                  \n"," multi_head_attention (MultiHea  (None, None, 128)   66048       ['broadcast_positional_encoding[0\n"," dAttention)                                                     ][0]',                           \n","                                                                  'broadcast_positional_encoding[0\n","                                                                 ][0]']                           \n","                                                                                                  \n"," dropout (Dropout)              (None, None, 128)    0           ['multi_head_attention[0][0]']   \n","                                                                                                  \n"," tf.__operators__.add_1 (TFOpLa  (None, None, 128)   0           ['broadcast_positional_encoding[0\n"," mbda)                                                           ][0]',                           \n","                                                                  'dropout[0][0]']                \n","                                                                                                  \n"," layer_normalization (LayerNorm  (None, None, 128)   256         ['tf.__operators__.add_1[0][0]'] \n"," alization)                                                                                       \n","                                                                                                  \n"," dense_2 (Dense)                (None, None, 256)    33024       ['layer_normalization[0][0]']    \n","                                                                                                  \n"," dense_3 (Dense)                (None, None, 128)    32896       ['dense_2[0][0]']                \n","                                                                                                  \n"," dropout_1 (Dropout)            (None, None, 128)    0           ['dense_3[0][0]']                \n","                                                                                                  \n"," tf.__operators__.add_2 (TFOpLa  (None, None, 128)   0           ['dropout_1[0][0]',              \n"," mbda)                                                            'dense_3[0][0]']                \n","                                                                                                  \n"," layer_normalization_1 (LayerNo  (None, None, 128)   256         ['tf.__operators__.add_2[0][0]'] \n"," rmalization)                                                                                     \n","                                                                                                  \n"," multi_head_attention_1 (MultiH  (None, None, 128)   66048       ['layer_normalization_1[0][0]',  \n"," eadAttention)                                                    'layer_normalization_1[0][0]']  \n","                                                                                                  \n"," dropout_2 (Dropout)            (None, None, 128)    0           ['multi_head_attention_1[0][0]'] \n","                                                                                                  \n"," tf.__operators__.add_3 (TFOpLa  (None, None, 128)   0           ['layer_normalization_1[0][0]',  \n"," mbda)                                                            'dropout_2[0][0]']              \n","                                                                                                  \n"," layer_normalization_2 (LayerNo  (None, None, 128)   256         ['tf.__operators__.add_3[0][0]'] \n"," rmalization)                                                                                     \n","                                                                                                  \n"," dense_4 (Dense)                (None, None, 256)    33024       ['layer_normalization_2[0][0]']  \n","                                                                                                  \n"," dense_5 (Dense)                (None, None, 128)    32896       ['dense_4[0][0]']                \n","                                                                                                  \n"," dropout_3 (Dropout)            (None, None, 128)    0           ['dense_5[0][0]']                \n","                                                                                                  \n"," tf.__operators__.add_4 (TFOpLa  (None, None, 128)   0           ['dropout_3[0][0]',              \n"," mbda)                                                            'dense_5[0][0]']                \n","                                                                                                  \n"," layer_normalization_3 (LayerNo  (None, None, 128)   256         ['tf.__operators__.add_4[0][0]'] \n"," rmalization)                                                                                     \n","                                                                                                  \n"," multi_head_attention_2 (MultiH  (None, None, 128)   66048       ['layer_normalization_3[0][0]',  \n"," eadAttention)                                                    'layer_normalization_3[0][0]']  \n","                                                                                                  \n"," dropout_4 (Dropout)            (None, None, 128)    0           ['multi_head_attention_2[0][0]'] \n","                                                                                                  \n"," tf.__operators__.add_5 (TFOpLa  (None, None, 128)   0           ['layer_normalization_3[0][0]',  \n"," mbda)                                                            'dropout_4[0][0]']              \n","                                                                                                  \n"," layer_normalization_4 (LayerNo  (None, None, 128)   256         ['tf.__operators__.add_5[0][0]'] \n"," rmalization)                                                                                     \n","                                                                                                  \n"," dense_6 (Dense)                (None, None, 256)    33024       ['layer_normalization_4[0][0]']  \n","                                                                                                  \n"," dense_7 (Dense)                (None, None, 128)    32896       ['dense_6[0][0]']                \n","                                                                                                  \n"," dropout_5 (Dropout)            (None, None, 128)    0           ['dense_7[0][0]']                \n","                                                                                                  \n"," tf.__operators__.add_6 (TFOpLa  (None, None, 128)   0           ['dropout_5[0][0]',              \n"," mbda)                                                            'dense_7[0][0]']                \n","                                                                                                  \n"," layer_normalization_5 (LayerNo  (None, None, 128)   256         ['tf.__operators__.add_6[0][0]'] \n"," rmalization)                                                                                     \n","                                                                                                  \n"," multi_head_attention_3 (MultiH  (None, None, 128)   66048       ['layer_normalization_5[0][0]',  \n"," eadAttention)                                                    'layer_normalization_5[0][0]']  \n","                                                                                                  \n"," dropout_6 (Dropout)            (None, None, 128)    0           ['multi_head_attention_3[0][0]'] \n","                                                                                                  \n"," tf.__operators__.add_7 (TFOpLa  (None, None, 128)   0           ['layer_normalization_5[0][0]',  \n"," mbda)                                                            'dropout_6[0][0]']              \n","                                                                                                  \n"," layer_normalization_6 (LayerNo  (None, None, 128)   256         ['tf.__operators__.add_7[0][0]'] \n"," rmalization)                                                                                     \n","                                                                                                  \n"," dense_8 (Dense)                (None, None, 256)    33024       ['layer_normalization_6[0][0]']  \n","                                                                                                  \n"," dense_9 (Dense)                (None, None, 128)    32896       ['dense_8[0][0]']                \n","                                                                                                  \n"," dropout_7 (Dropout)            (None, None, 128)    0           ['dense_9[0][0]']                \n","                                                                                                  \n"," tf.__operators__.add_8 (TFOpLa  (None, None, 128)   0           ['dropout_7[0][0]',              \n"," mbda)                                                            'dense_9[0][0]']                \n","                                                                                                  \n"," layer_normalization_7 (LayerNo  (None, None, 128)   256         ['tf.__operators__.add_8[0][0]'] \n"," rmalization)                                                                                     \n","                                                                                                  \n"," global_average_pooling1d (Glob  (None, 128)         0           ['layer_normalization_7[0][0]']  \n"," alAveragePooling1D)                                                                              \n","                                                                                                  \n"," dropout_8 (Dropout)            (None, 128)          0           ['global_average_pooling1d[0][0]'\n","                                                                 ]                                \n","                                                                                                  \n"," dense_10 (Dense)               (None, 14)           1806        ['dropout_8[0][0]']              \n","                                                                                                  \n"," softmax (Softmax)              (None, 14)           0           ['dense_10[0][0]']               \n","                                                                                                  \n","==================================================================================================\n","Total params: 540,814\n","Trainable params: 540,814\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","Shape of model output before softmax:  (None, 14)\n","Epoch 1/50\n","8197/8198 [============================>.] - ETA: 0s - loss: nan - accuracy: 0.7985\n","Epoch 1: val_accuracy improved from -inf to 0.79904, saving model to best_model.h5\n","8198/8198 [==============================] - 268s 30ms/step - loss: nan - accuracy: 0.7984 - val_loss: nan - val_accuracy: 0.7990 - lr: 2.0000e-04\n","Epoch 2/50\n","5281/8198 [==================>...........] - ETA: 1:22 - loss: nan - accuracy: 0.7986"]}]},{"cell_type":"code","source":["# Evaluate the model\n","y_pred = np.argmax(model.predict(X_test), axis=-1)\n","print(\"Classification Report:\")\n","print(classification_report(y_test, y_pred))\n","\n","# Plot ROC curve\n","y_score = model.predict(X_test)\n","\n","model_name = 'transformer_ids_model'\n","plot_roc_curve(y_test, y_score, le, model_name)\n","\n","label_encoder = le\n","# Print scores\n","print_score(y_pred, y_test, y_score, label_encoder, model_name)\n","plot_roc_curve(y_test, y_score, label_encoder, model_name)\n","plot_precision_recall_curve(y_test, y_score, label_encoder, model_name)\n","plot_class_accuracy(y_test, y_pred, label_encoder, model_name)\n","plot_class_f1_score(y_test, y_pred, label_encoder, model_name)"],"metadata":{"id":"lwRcigYMQQY1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["input_shape = X.shape[1:]\n","print(\"Input shape:\", input_shape)\n","print(\"embeddings_with_pos_enc shape:\", embeddings_with_pos_enc.shape)\n","num_classes = len(np.unique(y))\n","print(\"Number of classes:\", num_classes)\n","print(\"X_train shape:\", X_train.shape)\n","print(\"y_train shape:\", y_train.shape)\n","print(\"X_test shape:\", X_test.shape)\n","print(\"y_test shape:\", y_test.shape)"],"metadata":{"id":"Bp2hKXOY5Wbl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1686502933632,"user_tz":-60,"elapsed":458,"user":{"displayName":"Ray Mac Raois","userId":"15450155140228807087"}},"outputId":"d69226f3-764e-448a-ab0b-9a8c705f5188"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Input shape: (70,)\n","embeddings_with_pos_enc shape: (70, 128)\n","Number of classes: 15\n","X_train shape: (524671, 70)\n","y_train shape: (524671,)\n","X_test shape: (131168, 70)\n","y_test shape: (131168,)\n"]}]},{"cell_type":"code","source":["import tensorflow as tf\n","print(tf.__version__)\n"],"metadata":{"id":"5Mw0XUjtY6ZE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# from tensorflow.keras.models import Sequential\n","# from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout\n","# from tensorflow.keras.utils import to_categorical\n","\n","\n","# # Scale the features\n","# scaler = StandardScaler()\n","# X_train_scaled = scaler.fit_transform(X_train)\n","# X_test_scaled = scaler.transform(X_test)\n","\n","# # Reshape the input data into 3D format for use with Conv1D (samples, timesteps, features)\n","# X_train_scaled = X_train_scaled.reshape(X_train_scaled.shape[0], X_train_scaled.shape[1], 1)\n","# X_test_scaled = X_test_scaled.reshape(X_test_scaled.shape[0], X_test_scaled.shape[1], 1)\n","\n","\n","# # Define the CNN architecture\n","# model = Sequential()\n","# model.add(Conv1D(32, kernel_size=3, activation='relu', input_shape=(X_train_scaled.shape[1], 1)))\n","# model.add(MaxPooling1D(pool_size=2))\n","# model.add(Conv1D(64, kernel_size=3, activation='relu'))\n","# model.add(MaxPooling1D(pool_size=2))\n","# model.add(Flatten())\n","# model.add(Dense(128, activation='relu'))\n","# model.add(Dropout(0.5))\n","# model.add(Dense(len(label_encoder.classes_), activation='softmax'))\n","\n","# # Compile the model\n","# model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","# early_stopping = EarlyStopping(monitor='val_loss', patience=5, mode='min')\n","# # Train the model\n","# model.fit(X_train_scaled, y_train, batch_size=64, epochs=50, validation_split=0.2,  callbacks=[early_stopping])\n","# # Evaluate the model\n","# score = model.evaluate(X_test_scaled, y_test)\n","# print(\"Test loss:\", score[0])\n","# print(\"Test accuracy:\", score[1])\n","# # Make predictions\n","# y_pred = np.argmax(model.predict(X_test_scaled), axis=-1)\n","\n","# # Calculate prediction probabilities\n","# y_score = model.predict(X_test_scaled)\n","\n","# # Convert one-hot encoded y_test to class labels\n","# y_test_labels = np.argmax(y_test, axis=-1)\n","# model_name = \"CNN\"\n","# # Print scores\n","# print_score(y_pred, y_test_labels, y_score, label_encoder, model_name)\n","# plot_roc_curve(y_test_labels, y_score, label_encoder, model_name)\n","# plot_precision_recall_curve(y_test, y_score, label_encoder, model_name)\n","# plot_class_accuracy(y_test_labels, y_pred, label_encoder, model_name)\n","# plot_class_f1_score(y_test_labels, y_pred, label_encoder, model_name)"],"metadata":{"id":"IMptP-vmcWs-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"qvFhe2KsY60t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# from sklearn.linear_model import LogisticRegression\n","# # Train the Logistic Regression Classifier\n","# lr_classifier = LogisticRegression(max_iter=1000, random_state=42)\n","# lr_classifier.fit(X_train_scaled, y_train)\n","# # Make predictions\n","# y_pred = lr_classifier.predict(X_test_scaled)\n","# # Plot ROC curve\n","# y_score = lr_classifier.predict_proba(X_test_scaled)\n","\n","# model_name = 'LogisticRegression'\n","# plot_roc_curve(y_test, y_score, label_encoder, model_name)\n","# # Print scores\n","# print(\"LogisticRegression Classifier\")\n","# print_score(y_pred, y_test, y_score, label_encoder, model_name)\n","# plot_precision_recall_curve(y_test, y_score, label_encoder, model_name)\n","# plot_class_accuracy(y_test, y_pred, label_encoder, model_name)\n","# plot_class_f1_score(y_test, y_pred, label_encoder, model_name)"],"metadata":{"id":"aQy0GMJySy19"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# from sklearn.tree import DecisionTreeClassifier\n","# # Train the Decision Tree Classifier\n","# dt_classifier = DecisionTreeClassifier(random_state=42)\n","# dt_classifier.fit(X_train_scaled, y_train)\n","\n","# # Make predictions\n","# y_pred = dt_classifier.predict(X_test_scaled)\n","\n","# # Plot ROC curve\n","# y_score = dt_classifier.predict_proba(X_test_scaled)\n","\n","# model_name = 'DecisionTree'\n","# plot_roc_curve(y_test, y_score, label_encoder, model_name)\n","# # Print scores\n","# print(\"DecisionTree Classifier\")\n","# print_score(y_pred, y_test, y_score, label_encoder, model_name)\n","# plot_precision_recall_curve(y_test, y_score, label_encoder, model_name)\n","# plot_class_accuracy(y_test, y_pred, label_encoder, model_name)\n","# plot_class_f1_score(y_test, y_pred, label_encoder, model_name)"],"metadata":{"id":"91bf03p-Yv4d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# # Train the Random Forest Classifier\n","# rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n","# rf_classifier.fit(X_train_scaled, y_train)\n","\n","# # Make predictions\n","# y_pred = rf_classifier.predict(X_test_scaled)\n","\n","# # Plot ROC curve\n","# y_score = rf_classifier.predict_proba(X_test_scaled)\n","\n","# model_name = 'RandomForest'\n","# plot_roc_curve(y_test, y_score, label_encoder, model_name)\n","# # Print scores\n","# print(\"Random Forest Classifier\")\n","# print_score(y_pred, y_test, y_score, label_encoder, model_name)\n","# plot_precision_recall_curve(y_test, y_score, label_encoder, model_name)\n","# plot_class_accuracy(y_test, y_pred, label_encoder, model_name)\n","# plot_class_f1_score(y_test, y_pred, label_encoder, model_name)"],"metadata":{"id":"Ktn0lT8-XQ3c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# from sklearn.ensemble import AdaBoostClassifier\n","# # Train the AdaBoost Classifier\n","# adaboost_classifier = AdaBoostClassifier(random_state=42)\n","# adaboost_classifier.fit(X_train_scaled, y_train)\n","\n","# # Make predictions\n","# y_pred = adaboost_classifier.predict(X_test_scaled)\n","\n","# # Plot ROC curve\n","# y_score = adaboost_classifier.predict_proba(X_test_scaled)\n","# model_name = 'Adaboost'\n","# plot_roc_curve(y_test, y_score, label_encoder, model_name)\n","\n","# print(\"Adaboost \")\n","# print_score(y_pred, y_test, y_score, label_encoder, model_name)\n","# plot_precision_recall_curve(y_test, y_score, label_encoder, model_name)\n","# plot_class_accuracy(y_test, y_pred, label_encoder, model_name)\n","# plot_class_f1_score(y_test, y_pred, label_encoder, model_name)"],"metadata":{"id":"2qIARz0KZeaV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"T5PbryQ0Z4ER"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["reducing the majority classes in the CIC_IDS_2017 dataset by 75 percent actually marginally improved detection of minority classes"],"metadata":{"id":"WrZ7Qdk_Xel8"}},{"cell_type":"code","source":["# from sklearn.svm import SVC\n","# # Train the SVM Classifier\n","# svm_classifier = SVC(probability=True, random_state=42)\n","# svm_classifier.fit(X_train_scaled, y_train)\n","\n","# # Make predictions\n","# y_pred = svm_classifier.predict(X_test_scaled)\n","\n","# # Plot ROC curve\n","# y_score = svm_classifier.predict_proba(X_test_scaled)\n","\n","# model_name = 'SVM'\n","# plot_roc_curve(y_test, y_score, label_encoder, model_name)\n","# # Print scores\n","# print(\"SVM \")\n","# print_score(y_pred, y_test, y_score, label_encoder, model_name)\n","# plot_precision_recall_curve(y_test, y_score, label_encoder, model_name)\n","# plot_class_accuracy(y_test, y_pred, label_encoder, model_name)\n","# plot_class_f1_score(y_test, y_pred, label_encoder, model_name)"],"metadata":{"id":"VS7rxfsHZH7G"},"execution_count":null,"outputs":[]}]}